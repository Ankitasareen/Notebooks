{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CAST_NO  GRADE   BLOW_DUR  MIXER_C  MIXER_MN  MIXER_S  MIXER_P  MIXER_SI  \\\n",
      "0     M44919    980  18.766667     4.48    0.0460   0.0590   0.1940    0.6450   \n",
      "1     M44923    980  18.183333     4.48    0.0460   0.0500   0.1870    0.6790   \n",
      "2     M44925    980  18.166667     4.48    0.0420   0.0780   0.1900    0.8090   \n",
      "3     M44927    980  17.616667     4.48    0.0470   0.0570   0.1980    0.7550   \n",
      "4     M44931    980  18.350000     4.48    0.0440   0.0640   0.1980    0.7920   \n",
      "...      ...    ...        ...      ...       ...      ...      ...       ...   \n",
      "8143  M60321    980  16.333333     4.65    0.0529   0.0250   0.1704    0.9286   \n",
      "8144  M60325    909  16.683333     4.29    0.0438   0.0400   0.1679    0.5499   \n",
      "8145  M60330    909  15.850000     4.48    0.0434   0.0368   0.1736    0.7030   \n",
      "8146  M60344    980  16.850000     4.55    0.0431   0.0510   0.1573    0.6491   \n",
      "8147  M60348    980  16.350000     4.62    0.0431   0.0410   0.1773    0.7617   \n",
      "\n",
      "      MIXER_TI  HM_CHARGED    LIME  IRON_ORE   OXY  SCRAP  SCRAP_HVY_MELT  \\\n",
      "0       0.0655      140.00   8.498     2.906  7897  21.10            3.10   \n",
      "1       0.0656      140.22   8.590     3.000  7354  21.50            3.50   \n",
      "2       0.0700      144.96   8.807     3.165  7624  20.00            0.00   \n",
      "3       0.0729      140.00   9.000     4.500  7200  20.00            5.00   \n",
      "4       0.0679      135.00   8.217     3.248  7230  20.97            5.97   \n",
      "...        ...         ...     ...       ...   ...    ...             ...   \n",
      "8143    0.0995      144.15   8.187     7.589  7188  15.16            5.16   \n",
      "8144    0.0634      146.63   8.773     5.846  7540  15.81            5.81   \n",
      "8145    0.0709      152.37   8.629     8.269  6724   0.00            0.00   \n",
      "8146    0.0631      158.69  10.217    11.905  7234   0.00            0.00   \n",
      "8147    0.0723      155.95   9.029     8.645  6867   0.00            0.00   \n",
      "\n",
      "      SCRAP_WRP_OH_GRADE_FINES   TD_P   TD_C  \n",
      "0                         18.0  0.010  0.042  \n",
      "1                         18.0  0.021  0.050  \n",
      "2                         20.0  0.022  0.053  \n",
      "3                          5.0  0.015  0.046  \n",
      "4                         15.0  0.019  0.054  \n",
      "...                        ...    ...    ...  \n",
      "8143                       5.0  0.015  0.052  \n",
      "8144                       5.0  0.020  0.048  \n",
      "8145                       0.0  0.016  0.057  \n",
      "8146                       0.0  0.020  0.074  \n",
      "8147                       0.0  0.018  0.075  \n",
      "\n",
      "[8148 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel (r'heat data.xlsx')\n",
    "df =data.copy()\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAST_NO</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>BLOW_DUR</th>\n",
       "      <th>MIXER_C</th>\n",
       "      <th>MIXER_MN</th>\n",
       "      <th>MIXER_S</th>\n",
       "      <th>MIXER_P</th>\n",
       "      <th>MIXER_SI</th>\n",
       "      <th>MIXER_TI</th>\n",
       "      <th>HM_CHARGED</th>\n",
       "      <th>LIME</th>\n",
       "      <th>IRON_ORE</th>\n",
       "      <th>OXY</th>\n",
       "      <th>SCRAP</th>\n",
       "      <th>SCRAP_HVY_MELT</th>\n",
       "      <th>SCRAP_WRP_OH_GRADE_FINES</th>\n",
       "      <th>TD_P</th>\n",
       "      <th>TD_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M44919</td>\n",
       "      <td>980</td>\n",
       "      <td>18.766667</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>140.00</td>\n",
       "      <td>8.498</td>\n",
       "      <td>2.906</td>\n",
       "      <td>7897</td>\n",
       "      <td>21.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M44923</td>\n",
       "      <td>980</td>\n",
       "      <td>18.183333</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.187</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>140.22</td>\n",
       "      <td>8.590</td>\n",
       "      <td>3.000</td>\n",
       "      <td>7354</td>\n",
       "      <td>21.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M44925</td>\n",
       "      <td>980</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>144.96</td>\n",
       "      <td>8.807</td>\n",
       "      <td>3.165</td>\n",
       "      <td>7624</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M44927</td>\n",
       "      <td>980</td>\n",
       "      <td>17.616667</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>140.00</td>\n",
       "      <td>9.000</td>\n",
       "      <td>4.500</td>\n",
       "      <td>7200</td>\n",
       "      <td>20.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M44931</td>\n",
       "      <td>980</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.0679</td>\n",
       "      <td>135.00</td>\n",
       "      <td>8.217</td>\n",
       "      <td>3.248</td>\n",
       "      <td>7230</td>\n",
       "      <td>20.97</td>\n",
       "      <td>5.97</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CAST_NO  GRADE   BLOW_DUR  MIXER_C  MIXER_MN  MIXER_S  MIXER_P  MIXER_SI  \\\n",
       "0  M44919    980  18.766667     4.48     0.046    0.059    0.194     0.645   \n",
       "1  M44923    980  18.183333     4.48     0.046    0.050    0.187     0.679   \n",
       "2  M44925    980  18.166667     4.48     0.042    0.078    0.190     0.809   \n",
       "3  M44927    980  17.616667     4.48     0.047    0.057    0.198     0.755   \n",
       "4  M44931    980  18.350000     4.48     0.044    0.064    0.198     0.792   \n",
       "\n",
       "   MIXER_TI  HM_CHARGED   LIME  IRON_ORE   OXY  SCRAP  SCRAP_HVY_MELT  \\\n",
       "0    0.0655      140.00  8.498     2.906  7897  21.10            3.10   \n",
       "1    0.0656      140.22  8.590     3.000  7354  21.50            3.50   \n",
       "2    0.0700      144.96  8.807     3.165  7624  20.00            0.00   \n",
       "3    0.0729      140.00  9.000     4.500  7200  20.00            5.00   \n",
       "4    0.0679      135.00  8.217     3.248  7230  20.97            5.97   \n",
       "\n",
       "   SCRAP_WRP_OH_GRADE_FINES   TD_P   TD_C  \n",
       "0                      18.0  0.010  0.042  \n",
       "1                      18.0  0.021  0.050  \n",
       "2                      20.0  0.022  0.053  \n",
       "3                       5.0  0.015  0.046  \n",
       "4                      15.0  0.019  0.054  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8148 entries, 0 to 8147\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   CAST_NO                   8148 non-null   object \n",
      " 1   GRADE                     8148 non-null   int64  \n",
      " 2   BLOW_DUR                  8148 non-null   float64\n",
      " 3   MIXER_C                   8148 non-null   float64\n",
      " 4   MIXER_MN                  8138 non-null   float64\n",
      " 5   MIXER_S                   8148 non-null   float64\n",
      " 6   MIXER_P                   8138 non-null   float64\n",
      " 7   MIXER_SI                  8138 non-null   float64\n",
      " 8   MIXER_TI                  8138 non-null   float64\n",
      " 9   HM_CHARGED                8148 non-null   float64\n",
      " 10  LIME                      8148 non-null   float64\n",
      " 11  IRON_ORE                  8148 non-null   float64\n",
      " 12  OXY                       8148 non-null   int64  \n",
      " 13  SCRAP                     8148 non-null   float64\n",
      " 14  SCRAP_HVY_MELT            8148 non-null   float64\n",
      " 15  SCRAP_WRP_OH_GRADE_FINES  8148 non-null   float64\n",
      " 16  TD_P                      8148 non-null   float64\n",
      " 17  TD_C                      8148 non-null   float64\n",
      "dtypes: float64(15), int64(2), object(1)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GRADE</th>\n",
       "      <th>BLOW_DUR</th>\n",
       "      <th>MIXER_C</th>\n",
       "      <th>MIXER_MN</th>\n",
       "      <th>MIXER_S</th>\n",
       "      <th>MIXER_P</th>\n",
       "      <th>MIXER_SI</th>\n",
       "      <th>MIXER_TI</th>\n",
       "      <th>HM_CHARGED</th>\n",
       "      <th>LIME</th>\n",
       "      <th>IRON_ORE</th>\n",
       "      <th>OXY</th>\n",
       "      <th>SCRAP</th>\n",
       "      <th>SCRAP_HVY_MELT</th>\n",
       "      <th>SCRAP_WRP_OH_GRADE_FINES</th>\n",
       "      <th>TD_P</th>\n",
       "      <th>TD_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8138.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8138.000000</td>\n",
       "      <td>8138.00000</td>\n",
       "      <td>8138.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "      <td>8148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>963.814801</td>\n",
       "      <td>17.605267</td>\n",
       "      <td>4.485996</td>\n",
       "      <td>0.055506</td>\n",
       "      <td>0.044751</td>\n",
       "      <td>0.424306</td>\n",
       "      <td>0.86496</td>\n",
       "      <td>0.071089</td>\n",
       "      <td>149.679074</td>\n",
       "      <td>9.163911</td>\n",
       "      <td>5.095398</td>\n",
       "      <td>7291.111807</td>\n",
       "      <td>11.745220</td>\n",
       "      <td>4.727301</td>\n",
       "      <td>4.276667</td>\n",
       "      <td>0.019110</td>\n",
       "      <td>0.049677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>110.438857</td>\n",
       "      <td>11.906233</td>\n",
       "      <td>0.182641</td>\n",
       "      <td>0.675929</td>\n",
       "      <td>0.015482</td>\n",
       "      <td>22.003005</td>\n",
       "      <td>9.90389</td>\n",
       "      <td>0.015795</td>\n",
       "      <td>9.645549</td>\n",
       "      <td>1.043217</td>\n",
       "      <td>2.423345</td>\n",
       "      <td>497.272627</td>\n",
       "      <td>7.367028</td>\n",
       "      <td>3.585349</td>\n",
       "      <td>4.733900</td>\n",
       "      <td>0.007956</td>\n",
       "      <td>0.052317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.016400</td>\n",
       "      <td>-0.009900</td>\n",
       "      <td>-0.048700</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.021600</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.016000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1583.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.019000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>980.000000</td>\n",
       "      <td>16.683333</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>0.63800</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>143.887500</td>\n",
       "      <td>8.526000</td>\n",
       "      <td>3.570000</td>\n",
       "      <td>7007.750000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.038000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>980.000000</td>\n",
       "      <td>17.516667</td>\n",
       "      <td>4.480000</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>0.178300</td>\n",
       "      <td>0.74300</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>9.030000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7270.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>5.470000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>980.000000</td>\n",
       "      <td>18.350000</td>\n",
       "      <td>4.520000</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.86000</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>155.982500</td>\n",
       "      <td>9.539000</td>\n",
       "      <td>6.651500</td>\n",
       "      <td>7581.000000</td>\n",
       "      <td>16.320000</td>\n",
       "      <td>7.192500</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.023000</td>\n",
       "      <td>0.055000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1081.000000</td>\n",
       "      <td>1047.383333</td>\n",
       "      <td>5.020000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>894.00000</td>\n",
       "      <td>0.210400</td>\n",
       "      <td>175.840000</td>\n",
       "      <td>15.949000</td>\n",
       "      <td>17.304000</td>\n",
       "      <td>9500.000000</td>\n",
       "      <td>23.770000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>21.950000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>4.380000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GRADE     BLOW_DUR      MIXER_C     MIXER_MN      MIXER_S  \\\n",
       "count  8148.000000  8148.000000  8148.000000  8138.000000  8148.000000   \n",
       "mean    963.814801    17.605267     4.485996     0.055506     0.044751   \n",
       "std     110.438857    11.906233     0.182641     0.675929     0.015482   \n",
       "min      26.000000     0.150000     0.000000    -0.016400    -0.009900   \n",
       "25%     980.000000    16.683333     4.480000     0.041400     0.037000   \n",
       "50%     980.000000    17.516667     4.480000     0.046000     0.043000   \n",
       "75%     980.000000    18.350000     4.520000     0.052000     0.050000   \n",
       "max    1081.000000  1047.383333     5.020000    61.000000     0.550000   \n",
       "\n",
       "           MIXER_P    MIXER_SI     MIXER_TI   HM_CHARGED         LIME  \\\n",
       "count  8138.000000  8138.00000  8138.000000  8148.000000  8148.000000   \n",
       "mean      0.424306     0.86496     0.071089   149.679074     9.163911   \n",
       "std      22.003005     9.90389     0.015795     9.645549     1.043217   \n",
       "min      -0.048700     0.00000    -0.021600    12.000000     1.016000   \n",
       "25%       0.166500     0.63800     0.060400   143.887500     8.526000   \n",
       "50%       0.178300     0.74300     0.070700   150.000000     9.030000   \n",
       "75%       0.190000     0.86000     0.081300   155.982500     9.539000   \n",
       "max    1985.000000   894.00000     0.210400   175.840000    15.949000   \n",
       "\n",
       "          IRON_ORE          OXY        SCRAP  SCRAP_HVY_MELT  \\\n",
       "count  8148.000000  8148.000000  8148.000000     8148.000000   \n",
       "mean      5.095398  7291.111807    11.745220        4.727301   \n",
       "std       2.423345   497.272627     7.367028        3.585349   \n",
       "min       0.000000  1583.000000     0.000000        0.000000   \n",
       "25%       3.570000  7007.750000    10.000000        0.000000   \n",
       "50%       5.000000  7270.000000    15.000000        5.470000   \n",
       "75%       6.651500  7581.000000    16.320000        7.192500   \n",
       "max      17.304000  9500.000000    23.770000       20.800000   \n",
       "\n",
       "       SCRAP_WRP_OH_GRADE_FINES         TD_P         TD_C  \n",
       "count               8148.000000  8148.000000  8148.000000  \n",
       "mean                   4.276667     0.019110     0.049677  \n",
       "std                    4.733900     0.007956     0.052317  \n",
       "min                    0.000000     0.005000     0.019000  \n",
       "25%                    0.000000     0.014000     0.038000  \n",
       "50%                    4.000000     0.018000     0.045000  \n",
       "75%                    6.000000     0.023000     0.055000  \n",
       "max                   21.950000     0.175000     4.380000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We see that there are some values in the dataset. Since there might be some outliers also,we will try to impute it with median.\n",
    "df[\"MIXER_MN\"].fillna(df[\"MIXER_MN\"].median(), inplace=True)\n",
    "df[\"MIXER_P\"].fillna(df[\"MIXER_P\"].median(), inplace=True)\n",
    "df[\"MIXER_SI\"].fillna(df[\"MIXER_SI\"].median(), inplace=True)\n",
    "df[\"MIXER_TI\"].fillna(df[\"MIXER_TI\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Feature Matrix is - (8148, 17)\n"
     ]
    }
   ],
   "source": [
    "#standardising the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(df)\n",
    "\n",
    "print (\"The shape of Feature Matrix is -\",X_std.shape)\n",
    "df=df.drop('TD_P',axis=1)\n",
    "df=df.drop('TD_C',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_std\n",
    "y=data['TD_P']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying the Random forest regression along with hyperparameter tuning. Below are the hypermaters that can be used for traing from which the best ones are to be chosen.\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 28.3min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 56.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 90,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0000 degrees.\n",
      "Accuracy = 99.99%.\n",
      "R2: 1.00\n"
     ]
    }
   ],
   "source": [
    "#evaluation of the model\n",
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_train,y_train)\n",
    "y_pred = best_random.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2: %.2f\" % r2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9639136190136564\n",
      "{'n_estimators': 30, 'max_features': 8}\n"
     ]
    }
   ],
   "source": [
    "#Another time hyperparamater tuning of Random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = RandomizedSearchCV(forest_reg, param_grid, cv=5,\n",
    "                          scoring='r2')\n",
    "grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this model we are getting scoring on the basis of r2 which is 0.963 which is considered better that that of having 1 because there might be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=8, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=30, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_random=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0001 degrees.\n",
      "Accuracy = 99.54%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "best_random = grid_search.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=3,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:linear', random_state=0,\n",
       "                                    reg_alpha=0, reg...\n",
       "                                    scale_pos_weight=1, seed=None, silent=None,\n",
       "                                    subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=5,\n",
       "             param_grid={'colsample_bytree': [0.7],\n",
       "                         'learning_rate': [0.03, 0.05, 0.07],\n",
       "                         'max_depth': [5, 6, 7], 'min_child_weight': [4],\n",
       "                         'n_estimators': [500], 'nthread': [4],\n",
       "                         'objective': ['reg:linear'], 'silent': [1],\n",
       "                         'subsample': [0.7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking for other algorithms like XGRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "xgb1 = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 10,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=0)\n",
    "\n",
    "xgb_grid.fit(X_train,\n",
    "         y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 500, 'nthread': 4, 'objective': 'reg:linear', 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0000 degrees.\n",
      "Accuracy = 99.77%.\n",
      "R2: 1.00\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "best_random = xgb_grid.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_train,y_train)\n",
    "y_pred = best_random.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2: %.2f\" % r2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': array([1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 0.e+00])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ridge regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# load the diabetes datasets\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0000 degrees.\n",
      "Accuracy = 100.00%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "best_random = grid.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking these models, we can say that might be there can be an overfitting therefor we will consider the one with the score 0.963."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
