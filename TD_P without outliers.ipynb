{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     CAST_NO  GRADE   BLOW_DUR  MIXER_C  MIXER_MN  MIXER_S  MIXER_P  MIXER_SI  \\\n",
      "0     M44919    980  18.766667     4.48    0.0460   0.0590   0.1940    0.6450   \n",
      "1     M44923    980  18.183333     4.48    0.0460   0.0500   0.1870    0.6790   \n",
      "2     M44925    980  18.166667     4.48    0.0420   0.0780   0.1900    0.8090   \n",
      "3     M44927    980  17.616667     4.48    0.0470   0.0570   0.1980    0.7550   \n",
      "4     M44931    980  18.350000     4.48    0.0440   0.0640   0.1980    0.7920   \n",
      "...      ...    ...        ...      ...       ...      ...      ...       ...   \n",
      "8143  M60321    980  16.333333     4.65    0.0529   0.0250   0.1704    0.9286   \n",
      "8144  M60325    909  16.683333     4.29    0.0438   0.0400   0.1679    0.5499   \n",
      "8145  M60330    909  15.850000     4.48    0.0434   0.0368   0.1736    0.7030   \n",
      "8146  M60344    980  16.850000     4.55    0.0431   0.0510   0.1573    0.6491   \n",
      "8147  M60348    980  16.350000     4.62    0.0431   0.0410   0.1773    0.7617   \n",
      "\n",
      "      MIXER_TI  HM_CHARGED    LIME  IRON_ORE   OXY  SCRAP  SCRAP_HVY_MELT  \\\n",
      "0       0.0655      140.00   8.498     2.906  7897  21.10            3.10   \n",
      "1       0.0656      140.22   8.590     3.000  7354  21.50            3.50   \n",
      "2       0.0700      144.96   8.807     3.165  7624  20.00            0.00   \n",
      "3       0.0729      140.00   9.000     4.500  7200  20.00            5.00   \n",
      "4       0.0679      135.00   8.217     3.248  7230  20.97            5.97   \n",
      "...        ...         ...     ...       ...   ...    ...             ...   \n",
      "8143    0.0995      144.15   8.187     7.589  7188  15.16            5.16   \n",
      "8144    0.0634      146.63   8.773     5.846  7540  15.81            5.81   \n",
      "8145    0.0709      152.37   8.629     8.269  6724   0.00            0.00   \n",
      "8146    0.0631      158.69  10.217    11.905  7234   0.00            0.00   \n",
      "8147    0.0723      155.95   9.029     8.645  6867   0.00            0.00   \n",
      "\n",
      "      SCRAP_WRP_OH_GRADE_FINES   TD_P   TD_C  \n",
      "0                         18.0  0.010  0.042  \n",
      "1                         18.0  0.021  0.050  \n",
      "2                         20.0  0.022  0.053  \n",
      "3                          5.0  0.015  0.046  \n",
      "4                         15.0  0.019  0.054  \n",
      "...                        ...    ...    ...  \n",
      "8143                       5.0  0.015  0.052  \n",
      "8144                       5.0  0.020  0.048  \n",
      "8145                       0.0  0.016  0.057  \n",
      "8146                       0.0  0.020  0.074  \n",
      "8147                       0.0  0.018  0.075  \n",
      "\n",
      "[8148 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel (r'heat data.xlsx')\n",
    "df =data.copy()\n",
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOxklEQVR4nO3dcaidd33H8ffnJquNDpvaXsUlYekwuOnIsBxcNmEE2zS2G0v/sOAYM9RAMHWbWwez2T/K9o/Cum7CjAbbGkGcUoWGIasxGmQwgzcqxtqNBofNXTt7pU02aoNr890f90k8SU7SnHPSe8/x937B4Ty/7/M79/ndP+7n/O7vPOd5UlVIktows9wDkCQtHUNfkhpi6EtSQwx9SWqIoS9JDVm53AO4lOuvv77Wr1+/3MOQpKly5MiRH1fV7KB9Ex3669evZ25ubrmHIUlTJckPL7bP5R1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+tKQNm7cSJKzj40bNy73kKTLZuhLQ9i4cSNHjx49p3b06FGDX1PD0JeGcH7gv1RdmjSGviQ1xNCXRnDvvffy3HPPce+99y73UKShZJLvnNXr9crLMGiSJLnovkn+W1Jbkhypqt6gfc70Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIS8Z+kkeSPJ0ku/11V6T5ECSx7vna7t6knw0ybEk301yY99rtnf9H0+y/eX5dSRJl3I5M/1PAe84r3YPcLCqNgAHuzbArcCG7rET2AOLbxLAB4HfBN4KfPDMG4Ukaem8ZOhX1deBZ84rbwP2ddv7gNv76p+uRd8AVid5PbAVOFBVz1TVs8ABLnwjkSS9zEZd039dVT0F0D2/tquvAY739ZvvaherXyDJziRzSeYWFhZGHJ4kaZAr/UHuoEsQ1iXqFxar9lZVr6p6s7OzV3RwktS6UUP/R92yDd3z0119HljX128t8OQl6tJUefOb3zxUXZo0o4b+fuDMGTjbgYf76u/uzuLZBJzsln8eAW5Jcm33Ae4tXU2aKo8++uhQdWnSrHypDkk+C2wGrk8yz+JZOB8GPp9kB/AEcEfX/UvAbcAx4CfAnQBV9UySvwG+2fX766o6/8Nh6cr50DUvy4+tD756yY/Jh06+PD9XTfLOWdIQztw5q//vZlBNWk6XunPWS870JV3oUrdNlCaZl2GQpIYY+pLUEENfkhrimr40gkEf5ErTwJm+NIIkfOITnzDwNXUMfWkI/TP89773vQPr0iRzeUcakgGvaWboS0MatKTjG4Gmhcs70hAutobv2r6mhTN9aQSevaNp5Uxfkhpi6EtSQ1zekUbgko6mlTN9aQgXO0vHs3c0LZzpS0My4DXNnOlLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1ZKzQT/LnSR5N8r0kn01ydZIbkhxO8niSzyW5quv7iq59rNu//kr8ApKkyzdy6CdZA/wp0KuqXwdWAO8CPgLcV1UbgGeBHd1LdgDPVtUbgPu6fpKkJTTu8s5KYFWSlcArgaeAtwMPdfv3Abd329u6Nt3+m+LthyRpSY0c+lX1X8DfAk+wGPYngSPAiap6oes2D6zpttcAx7vXvtD1v+78n5tkZ5K5JHMLCwujDk+SNMA4yzvXsjh7vwH4JeBVwK0Dup65zdCgWf0FtyCqqr1V1auq3uzs7KjDkyQNMM7yzs3Af1bVQlX9H/BF4LeB1d1yD8Ba4Mluex5YB9DtvwZ4ZozjS5KGNE7oPwFsSvLKbm3+JuD7wNeAd3Z9tgMPd9v7uzbd/q+WNxuVpCU1zpr+YRY/kP0WcLT7WXuBDwB3JznG4pr9/d1L7geu6+p3A/eMMW5J0ggyyZPtXq9Xc3Nzyz0MSZoqSY5UVW/QPr+RK0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDVn50l0k9Rt0G4hJ/ma71M+ZvjSEM4E/MzPDV77yFWZmZs6pS5POmb40pJmZGV588UUAXnzxRVasWMHp06eXeVTS5XGmLw3py1/+8iXb0iQz9KUh3XLLLZdsS5PM0JeGdPr0aVasWMHBgwdd2tHUcU1fGkJVkYTTp09z8803n1OXpoGhLw3JgNc0c3lHkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqyFihn2R1koeS/HuSx5L8VpLXJDmQ5PHu+dqub5J8NMmxJN9NcuOV+RUkSZdr3Jn+PwD/UlW/CvwG8BhwD3CwqjYAB7s2wK3Ahu6xE9gz5rElSUMaOfSTvBr4HeB+gKr6aVWdALYB+7pu+4Dbu+1twKdr0TeA1UleP/LIJUlDG2em/yvAAvBgkm8n+WSSVwGvq6qnALrn13b91wDH+14/39XOkWRnkrkkcwsLC2MMT5J0vnFCfyVwI7Cnqt4CPMfPlnIGyYDaBRcmr6q9VdWrqt7s7OwYw5MknW+c0J8H5qvqcNd+iMU3gR+dWbbpnp/u67+u7/VrgSfHOL4kaUgjh35V/TdwPMkbu9JNwPeB/cD2rrYdeLjb3g+8uzuLZxNw8swykDRNZmZmSHL2MTPjmc+aHuPeLvFPgM8kuQr4AXAni28kn0+yA3gCuKPr+yXgNuAY8JOurzRVZmZmqCquvvpqDh06xObNmzl16hQzMzPeIF1TYazQr6rvAL0Bu24a0LeA941zPGm5nQn8559/HoDnn3+eVatWcerUqWUemXR5/L9UGtKhQ4cu2ZYmmaEvDWnz5s2XbEuTzNCXhpCEU6dOsWrVKg4fPnx2aScZdEayNHnG/SBXasrp06eZmZnh1KlTbNq0CVh8I/BDXE0LQ18akgGvaebyjiQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcRv5EpDGnSdncUrh0uTz5m+NISLXVjNC65pWjjTl0bQP7M38DVNnOlLUkMMfUlqiMs70ghc0tG0cqYvDeFiZ+l49o6mhaEvDWHr1q0A7Nq1ixMnTrBr165z6tKkc3lHGsKBAwfYtWsXH/vYxwDOPn/84x9fzmFJly2T/G9pr9erubm55R6GdFYSTpw4wTXXXHO2dvLkSVavXu0SjyZGkiNV1Ru0z+UdaQhJ2L179zm13bt3+8GupoahLw1hy5Yt7Nmzh7vuuouTJ09y1113sWfPHrZs2bLcQ5Mui8s70pC2bt3KgQMHqCqSsGXLFh555JHlHpZ01qWWd/wgVxqSAa9p5vKOJDVk7NBPsiLJt5P8c9e+IcnhJI8n+VySq7r6K7r2sW7/+nGPLUkazpWY6b8feKyv/RHgvqraADwL7OjqO4Bnq+oNwH1dP0nSEhor9JOsBX4X+GTXDvB24KGuyz7g9m57W9em239TPM9NkpbUuDP9vwf+Ejjdta8DTlTVC117HljTba8BjgN0+092/c+RZGeSuSRzCwsLYw5PktRv5NBP8nvA01V1pL88oGtdxr6fFar2VlWvqnqzs7OjDk+SNMA4p2y+Dfj9JLcBVwOvZnHmvzrJym42vxZ4sus/D6wD5pOsBK4Bnhnj+JKkIY0806+q3VW1tqrWA+8CvlpVfwh8DXhn12078HC3vb9r0+3/ak3yN8Mk6efQy3Ge/geAu5McY3HN/v6ufj9wXVe/G7jnZTi2JOkSrsg3cqvqEHCo2/4B8NYBfU4Bd1yJ40mSRuM3ciWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktSQkUM/ybokX0vyWJJHk7y/q78myYEkj3fP13b1JPlokmNJvpvkxiv1S0iSLs84M/0XgL+oql8DNgHvS/Im4B7gYFVtAA52bYBbgQ3dYyewZ4xjS5JGMHLoV9VTVfWtbvt/gceANcA2YF/XbR9we7e9Dfh0LfoGsDrJ60ceuSRpaFdkTT/JeuAtwGHgdVX1FCy+MQCv7bqtAY73vWy+q53/s3YmmUsyt7CwcCWGJ0nqjB36SX4R+ALwZ1X1P5fqOqBWFxSq9lZVr6p6s7Oz4w5PktRnrNBP8gssBv5nquqLXflHZ5Ztuuenu/o8sK7v5WuBJ8c5viRpOOOcvRPgfuCxqvq7vl37ge3d9nbg4b76u7uzeDYBJ88sA0mSlsbKMV77NuCPgKNJvtPV/gr4MPD5JDuAJ4A7un1fAm4DjgE/Ae4c49iSpBGMHPpV9a8MXqcHuGlA/wLeN+rxJEnj8xu5ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhqxc7gFI0ybJBbWqWoaRSMNzpi8NoT/w77zzzoF1aZIZ+tIIqooHHnjAGb6mjqEvDal/hj+oLU2yTPJMpdfr1dzc3HIPQzrrzDJO/9/NoJq0nJIcqareoH1LPtNP8o4k/5HkWJJ7lvr40pWQhPe85z2u5WvqLGnoJ1kB/CNwK/Am4A+SvGkpxyCNo382/+CDDw6sS5NsqWf6bwWOVdUPquqnwD8B25Z4DNJYquqChzQtljr01wDH+9rzXe2sJDuTzCWZW1hYWNLBSdLPu6UO/UELoOdMk6pqb1X1qqo3Ozu7RMOSpDYsdejPA+v62muBJ5d4DJLUrKUO/W8CG5LckOQq4F3A/iUegyQ1a0mvvVNVLyT5Y+ARYAXwQFU9upRjkKSWTfSXs5IsAD9c7nFIF3E98OPlHoQ0wC9X1cAPRSc69KVJlmTuYt96lCaV196RpIYY+pLUEENfGt3e5R6ANCzX9CWpIc70Jakhhr4kNcTQl4aU5IEkTyf53nKPRRqWoS8N71PAO5Z7ENIoDH1pSFX1deCZ5R6HNApDX5IaYuhLUkMMfUlqiKEvSQ0x9KUhJfks8G/AG5PMJ9mx3GOSLpeXYZCkhjjTl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIf8PkunQnYPbtusAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAOe0lEQVR4nO3dcYhVZ3rH8e/jqIlrXUeTSUhVasrKdsJA2XBJ066UztpuY7ZU/9hApDQSBgSJ7rYpdNP6x5aWQBZK042UgMR0DSzTDelihhK6BDPLMtCEjLtL1mhBSbNxahpn0dhSSZykT/+YVzPRiZl7r947+n4/MNxznvOee575I7/7+t5zJpGZSJLqsKDbDUiSOsfQl6SKGPqSVBFDX5IqYuhLUkUWdruBy7n55ptz7dq13W5Dkq4pBw8e/EVm9s12bF6H/tq1axkfH+92G5J0TYmIn3/SMZd3JKkihr4kVcTQl6SKGPqSVBFDX5IqYuhLTRoeHmZgYICenh4GBgYYHh7udkvSnM3rWzal+WZ4eJhdu3axd+9e1q9fz9jYGENDQwBs2bKly91Jny7m859WbjQa6X36mk8GBgbYvXs3g4ODF2qjo6Ps3LmTQ4cOdbEz6SMRcTAzG7MeM/Sluevp6eG9995j0aJFF2pTU1PceOONfPjhh13sTPrI5ULfNX2pCf39/YyNjX2sNjY2Rn9/f5c6kppj6EtN2LVrF0NDQ4yOjjI1NcXo6ChDQ0Ps2rWr261Jc+IXuVITzn9Zu3PnTo4cOUJ/fz+PPvqoX+LqmuGaviRdZ1zTlyQBcwj9iHg6Ik5GxKEZtZUR8WJEHC2vK0o9IuKJiDgWEa9FxJ0zztlaxh+NiK1X59eRJF3OXGb63wHuuaj2CHAgM9cBB8o+wEZgXfnZBjwJ0x8SwDeB3wDuAr55/oNCktQ5nxr6mfkj4NRF5U3AvrK9D9g8o/5MTnsZ6I2I24DfB17MzFOZeRp4kUs/SCRJV1mra/q3ZubbAOX1llJfBRyfMW6i1D6pfomI2BYR4xExPjk52WJ7kqTZXOkvcmOWWl6mfmkxc09mNjKz0dc36//iUZLUolZD/52ybEN5PVnqE8CaGeNWAycuU5ckdVCroT8CnL8DZyvw/Iz6A+UunruBM2X55wfAlyNiRfkC98ulJknqoE99IjcihoHfAW6OiAmm78J5DHg2IoaAt4D7yvAXgHuBY8BZ4EGAzDwVEX8DvFrG/XVmXvzlsCTpKvOJXEm6zvhEriQJMPQlqSqGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUkbZCPyL+NCJej4hDETEcETdGxO0R8UpEHI2I70XE4jL2hrJ/rBxfeyV+AUnS3LUc+hGxCvga0MjMAaAHuB/4FvB4Zq4DTgND5ZQh4HRmfg54vIyTJHVQu8s7C4ElEbEQ+AzwNvAl4LlyfB+wuWxvKvuU4xsiItq8viSpCS2Hfmb+J/C3wFtMh/0Z4CDwbmZ+UIZNAKvK9irgeDn3gzL+povfNyK2RcR4RIxPTk622p4kaRbtLO+sYHr2fjvwy8BSYOMsQ/P8KZc59lEhc09mNjKz0dfX12p7kqRZtLO887vAf2TmZGZOAd8HfgvoLcs9AKuBE2V7AlgDUI4vB061cX1JUpPaCf23gLsj4jNlbX4DcBgYBb5axmwFni/bI2WfcvylzLxkpi9JunraWdN/hekvZH8M/Ky81x7gG8DDEXGM6TX7veWUvcBNpf4w8EgbfUuSWhDzebLdaDRyfHy8221I0jUlIg5mZmO2Yz6RK0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUkbZCPyJ6I+K5iPj3iDgSEb8ZESsj4sWIOFpeV5SxERFPRMSxiHgtIu68Mr+CJGmu2p3pfxv418z8NeDXgSPAI8CBzFwHHCj7ABuBdeVnG/Bkm9eWJDWp5dCPiM8Cvw3sBcjMc5n5LrAJ2FeG7QM2l+1NwDM57WWgNyJua7lzSVLT2pnp/yowCfxjRPwkIp6KiKXArZn5NkB5vaWMXwUcn3H+RKl9TERsi4jxiBifnJxsoz1J0sXaCf2FwJ3Ak5n5BeB/+WgpZzYxSy0vKWTuycxGZjb6+vraaE+SdLF2Qn8CmMjMV8r+c0x/CLxzftmmvJ6cMX7NjPNXAyfauL4kqUkth35m/hdwPCI+X0obgMPACLC11LYCz5ftEeCBchfP3cCZ88tAkqTOWNjm+TuB70bEYuAN4EGmP0iejYgh4C3gvjL2BeBe4BhwtoyVJHVQW6GfmT8FGrMc2jDL2AQeaud6kqT2+ESuJFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKtJ26EdET0T8JCL+pezfHhGvRMTRiPheRCwu9RvK/rFyfG2715YkNedKzPS/DhyZsf8t4PHMXAecBoZKfQg4nZmfAx4v4yRJHdRW6EfEauArwFNlP4AvAc+VIfuAzWV7U9mnHN9QxkuSOqTdmf7fA38O/F/Zvwl4NzM/KPsTwKqyvQo4DlCOnynjPyYitkXEeESMT05OttmeJGmmlkM/Iv4AOJmZB2eWZxmaczj2USFzT2Y2MrPR19fXanuSpFksbOPcLwJ/GBH3AjcCn2V65t8bEQvLbH41cKKMnwDWABMRsRBYDpxq4/qSpCa1PNPPzL/IzNWZuRa4H3gpM/8IGAW+WoZtBZ4v2yNln3L8pcy8ZKYvSbp6rsZ9+t8AHo6IY0yv2e8t9b3ATaX+MPDIVbi2JOky2lneuSAzfwj8sGy/Adw1y5j3gPuuxPUkSa3xiVxJqoihL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRQx9SaqIoS9JFTH0Jakihr4kVcTQl6SKGPqSVBFDX5IqYuhLUkUMfUmqiKEvSRUx9CWpIoa+JFXE0Jekihj6klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXpIq0HPoRsSYiRiPiSES8HhFfL/WVEfFiRBwtrytKPSLiiYg4FhGvRcSdV+qXkCTNTTsz/Q+AP8vMfuBu4KGIuAN4BDiQmeuAA2UfYCOwrvxsA55s49qSpBa0HPqZ+XZm/rhs/w9wBFgFbAL2lWH7gM1lexPwTE57GeiNiNta7lyS1LQrsqYfEWuBLwCvALdm5tsw/cEA3FKGrQKOzzhtotQufq9tETEeEeOTk5NXoj1JUtF26EfELwH/DPxJZv735YbOUstLCpl7MrORmY2+vr5225MkzdBW6EfEIqYD/7uZ+f1Sfuf8sk15PVnqE8CaGaevBk60c31JUnPauXsngL3Akcz8uxmHRoCtZXsr8PyM+gPlLp67gTPnl4EkSZ2xsI1zvwj8MfCziPhpqf0l8BjwbEQMAW8B95VjLwD3AseAs8CDbVxbktSClkM/M8eYfZ0eYMMs4xN4qNXrSZLa5xO5klQRQ1+SKmLoS1JFDH1JqoihL0kVMfQlqSKGviRVxNCXmjQ8PMzAwAA9PT0MDAwwPDzc7ZakOWvniVypOsPDw+zatYu9e/eyfv16xsbGGBoaAmDLli1d7k76dDH9oOz81Gg0cnx8vNttSBcMDAywefNm9u/fz5EjR+jv77+wf+jQoW63JwEQEQczszHbMWf6UhMOHz7M2bNnL5npv/nmm91uTZoT1/SlJixevJgdO3YwODjIokWLGBwcZMeOHSxevLjbrUlzYuhLTTh37hy7d+9mdHSUqakpRkdH2b17N+fOnet2a9KcuLwjNeGOO+5g3bp1bNy4kffff58bbriBjRs3snTp0m63Js2JM32pCYODg4yMjNDb2wtAb28vIyMjDA4OdrkzaW4MfakJ+/fvZ9myZSxZsoQFCxawZMkSli1bxv79+7vdmjQnhr7UhImJCbZv335hOWfp0qVs376diYmJLncmzY336UtNiAgWLVrE1NTUhdr5/fn835Lqcrn79J3pS02aGfiz7UvzmaEvSRUx9KUWrFix4mOv0rXC0JdasHz5chYsWMDy5cu73YrUFB/Oklpw/m/t+Dd3dK1xpi9JFTH0Jakihr4kVcTQl6SKGPqSVBHv3tF1aeXKlZw+fbqj14yIK/6eK1as4NSpU1f8fVWvjod+RNwDfBvoAZ7KzMc63YOuf6e+9iHw2W63cQV82O0GdJ3paOhHRA/wD8DvARPAqxExkpmHO9mHKvBXZ67K215uNu8fXNO1oNNr+ncBxzLzjcw8B/wTsKnDPUhStTod+quA4zP2J0rtgojYFhHjETE+OTnZ0eYk6XrX6dCf7d/GH/s3cWbuycxGZjb6+vo61JYk1aHToT8BrJmxvxo40eEeJKlanQ79V4F1EXF7RCwG7gdGOtyD1LJP+rLWL3F1rejo3TuZ+UFE7AB+wPQtm09n5uud7EFqlwGva1nH79PPzBeAFzp9XUmSf4ZBkqpi6EtSRQx9SaqIoS9JFYn5fCdCREwCP+92H9InuBn4RbebkGbxK5k569Ot8zr0pfksIsYzs9HtPqRmuLwjSRUx9CWpIoa+1Lo93W5AapZr+pJUEWf6klQRQ1+SKmLoS02KiKcj4mREHOp2L1KzDH2ped8B7ul2E1IrDH2pSZn5I+BUt/uQWmHoS1JFDH1JqoihL0kVMfQlqSKGvtSkiBgG/g34fERMRMRQt3uS5so/wyBJFXGmL0kVMfQlqSKGviRVxNCXpIoY+pJUEUNfkipi6EtSRf4f3LudRiLuXjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAD4CAYAAADFAawfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANyUlEQVR4nO3db2gcd37H8c/XayEpZ5NaRDXFiauCw7HHOu3R5fogAqOj1HF7uE9vS/vEiw2GihgX6pZ9cPfEBkMpBdMHNZW5Qts9SttAMOeWQKeENdejq7vDyNWVHFclURPbCpJaXRKlm/W3Dyz538nSyJ7RfLV6v8BImh2Nvo/ejH8zu2PuLgBAXLuKHgAAsD5CDQDBEWoACI5QA0BwhBoAgtudx0FfeOEFHxkZyePQANCTJicnP3L34bVeyyXUIyMjarfbeRwaAHqSmb37pNdY+gCA4Ag1AARHqAEgOEINAMERagAIjlBjR2g2m6pUKiqVSqpUKmo2m0WPBKSW6vY8M5uRtCSpK+lzd6/mORSQpWazqUajoYmJCY2OjqrVaqler0uSarVawdMBG7M0H3O6Euqqu3+U5qDVatW5jxpRVCoVXbp0SWNjY/e3JUmi8fFxTU1NFTgZ8ICZTT7pJJilD/S86elpzc7OPrL0MTs7q+np6aJHA1JJe0b9X5IWJLmkv3D3y2vsc0rSKUk6ePDgr7777hPfZANsqZdeeklLS0vat2+f3nvvPR08eFALCwvau3ev3n///aLHAyStf0ad9i3kr7r7B2b285LeMrMfufvbD++wEu/L0r2lj2eaGMjQJ598oqWlJQ0MDOju3bv69NNPtbS0pFKpVPRoQCqplj7c/YOVr3ckvSHpK3kOBWRpfn5ee/bs0eDgoHbt2qXBwUHt2bNH8/PzRY8GpLJhqM3sC2a2d/V7Sb8hiSsw2FYGBwc1MzOju3fvamZmRoODg0WPBKSWZuljv6Q3zGx1/79193/KdSogY7dv3173ZyCyDUPt7j+R9MtbMAsAYA3cngcAwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwaT+PGghn5YPCtuQYaR6wAeSFUGPbShvP9WJMgLEdEGqEMTQ0pIWFhS39m1mclT9u3759PJQAmSLUCGNhYSG3M9y1gryVfwt4FqkebrtZ1WrV2+125sdFj/vm80VPkJ1v/k/RE2CbyeLhtkD+Nhm3rTxzZS0bRSLU2La4mIidgvuoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwqUNtZiUz+4GZXc1zIADAozZzRv26pOm8BgEArC1VqM3sRUm/Jekv8x0HAPC4tGfUfybpDyXdfdIOZnbKzNpm1p6bm8tkOCBLAwMDj3wFtosNQ21mX5N0x90n19vP3S+7e9Xdq8PDw5kNCGRleXn5ka/AdpHmjPpVScfNbEbStyV91cz+OtepgBysPumFh89iu9kw1O7+x+7+oruPSPq6pH9x99/NfTIgI0NDQ5IePHZr9evqdiA67qNGz1tcXNTp06fV398vServ79fp06e1uLhY8GRAOpsKtbv/q7t/La9hgDyUy2UNDQ3p0KFD2rVrlw4dOqShoSGVy+WiRwNS4YwaPW9sbEwXL17UiRMntLS0pBMnTujixYsaGxsrejQgFUKNnpckic6dO6crV65o7969unLlis6dO6ckSYoeDUjFVi+sZKlarXq73c78uMDTKJVKWl5eVl9f3/1tnU5HAwMD6na7BU4GPGBmk+5eXes1zqjR88rlslqt1iPbWq0Wa9TYNgg1el6j0VC9XleSJOp0OkqSRPV6XY1Go+jRgFR2Fz0AkLdarSZJGh8f1/T0tMrlss6fP39/OxAda9QAEABr1ACwjRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDV2hGazqUqlolKppEqlomazWfRIQGq7ix4AyFuz2VSj0dDExIRGR0fVarVUr9clSbVareDpgI2Zu6+/g9mApLcl9ete2P/e3b+x3u9Uq1Vvt9uZDQk8i0qlokuXLmlsbOz+tiRJND4+rqmpqQInAx4ws0l3r675WopQm6QvuPtPzaxPUkvS6+7+b0/6HUKNSEqlkpaXl9XX13d/W6fT0cDAgLrdboGTAQ+sF+oN16j9np+u/Ni38m/9ugOBlMtltVqtR7a1Wi2Vy+WCJgI2J9XFRDMrmdkPJd2R9Ja7f2+NfU6ZWdvM2nNzc1nPCTy1RqOher2uJEnU6XSUJInq9boajUbRowGppLqY6O5dSb9iZj8n6Q0zq7j71GP7XJZ0Wbq39JH5pMBTWr1gOD4+runpaZXLZZ0/f54Lidg2Nlyj/plfMPuGpI/d/U+etA9r1ACwOc+0Rm1mwytn0jKzQUm/LulH2Y4IAHiSNEsfvyDpr8yspHth/zt3v5rvWACAVRuG2t1vSPryFswCAFgDbyEHgOAINQAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWoACI5QA0BwG4bazF4ys8TMps3sppm9vhWDAQDu2Z1in88l/YG7f9/M9kqaNLO33P0/cp4NAKAUZ9Tu/qG7f3/l+yVJ05IO5D0YAOCeTa1Rm9mIpC9L+t4ar50ys7aZtefm5rKZDgCQPtRmtkfSP0g64+7/+/jr7n7Z3avuXh0eHs5yRgDY0VKF2sz6dC/Sf+Pu/5jvSACAh6W568MkTUiadvc/zX8kAMDD0pxRvyrp9yR91cx+uPLvN3OeCwCwYsPb89y9Jcm2YBYAwBp4ZyIABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1AAQHKEGgOAINQAER6gBIDhCDQDBEWrsCM1mU5VKRaVSSZVKRc1ms+iRgNTSPDMR2NaazaYajYYmJiY0OjqqVquler0uSarVagVPB2zM3D3zg1arVW+325kfF3galUpFly5d0tjY2P1tSZJofHxcU1NTBU4GPGBmk+5eXfM1Qo1eVyqVtLy8rL6+vvvbOp2OBgYG1O12C5wMeGC9ULNGjZ5XLpfVarUe2dZqtVQulwuaCNgcQo2e12g0VK/XlSSJOp2OkiRRvV5Xo9EoejQgFS4mouetXjAcHx/X9PS0yuWyzp8/z4VEbBusUQNAAKxRA8A2RqgBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMFtGGozu2Jmd8yMT1gHgAKkOaP+lqTXcp4DAPAEG4ba3d+WNL8FswAA1sAaNQAEl1mozeyUmbXNrD03N5fVYQFgx8ss1O5+2d2r7l4dHh7O6rAAsOOx9AEAwaW5Pa8p6buSvmhms2ZWz38sAMCqDR9u6+48ARQACsTSBwAER6gBIDhCDQDBEWoACI5QA0BwhBoAgiPUABAcoQaA4Ag1AARHqAEgOEINAMERagAIjlADQHCEGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAiOUANAcIQaAIIj1NgRms2mKpWKSqWSKpWKms1m0SMBqe0uegAgb81mU41GQxMTExodHVWr1VK9Xpck1Wq1gqcDNmbunvlBq9Wqt9vtzI8LPI1KpaKXX35Z165d02effab+/n4dO3ZM77zzjqampooeD5Akmdmku1fXeo2lD/S8mzdv6urVq7pw4YI+/vhjXbhwQVevXtXNmzeLHg1IhVCj55mZTp48qbNnz+q5557T2bNndfLkSZlZ0aMBqRBq9Dx317Vr15QkiTqdjpIk0bVr15THsh+QBy4mouf19/frwIEDOnbs2P016mq1qg8//LDo0YBUOKNGzzty5IiuX7+uTqcjSep0Orp+/bqOHDlS8GRAOoQaPa/dbsvM7q9Jr37PnUnYLlKF2sxeM7P/NLMfm9kf5T0UkKX5+Xnt379f3W5XktTtdrV//37Nz88XPBmQzoahNrOSpD+XdEzSlyTVzOxLeQ8GZOnWrVs6fvy45ubmdPz4cd26davokYDU0pxRf0XSj939J+7+f5K+Lem38x0LyFapVNKZM2f0/PPP68yZMyqVSkWPBKSW5q6PA5Lef+jnWUm/9vhOZnZK0ilJOnjwYCbDAVnpdruq1Wq6ffv2I8sgwHaQ5ox6rXcF/MwNqO5+2d2r7l4dHh5+9smADI2MjGhxcVGStLi4qJGRkWIHAjYhTahnJb300M8vSvogn3GA7B0+fFgzMzM6evSo5ubmdPToUc3MzOjw4cNFjwakkmbp498lvWxmvyTpvyV9XdLv5DoVkKEbN27olVde0ZtvvqnV/+0dPnxYN27cKHgyIJ0NQ+3un5vZ70v6Z0klSVfcnU+zwbZClLGdpXoLubt/R9J3cp4FALAG3pkIAMERagAIjlADQHCEGgCCy+WZiWY2J+ndzA8MPLsXJH1U9BDAGn7R3dd8t2AuoQaiMrP2kx4gCkTF0gcABEeoASA4Qo2d5nLRAwCbxRo1AATHGTUABEeoASA4Qo0dwcyumNkdM5sqehZgswg1dopvSXqt6CGAp0GosSO4+9uS5oueA3gahBoAgiPUABAcoQaA4Ag1AARHqLEjmFlT0nclfdHMZs2sXvRMQFq8hRwAguOMGgCCI9QAEByhBoDgCDUABEeoASA4Qg0AwRFqAAju/wGstr+etEcpDAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#We plot the boxplots of first three features and see that there are outliers which might can create problem.\n",
    "plt.boxplot(data['GRADE'])\n",
    "plt.show()\n",
    "plt.boxplot(data['BLOW_DUR'])\n",
    "plt.show()\n",
    "plt.boxplot(data['MIXER_C'])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRADE                         0.000000\n",
      "BLOW_DUR                      1.666667\n",
      "MIXER_C                       0.040000\n",
      "MIXER_MN                      0.010600\n",
      "MIXER_S                       0.013000\n",
      "MIXER_P                       0.023500\n",
      "MIXER_SI                      0.222000\n",
      "MIXER_TI                      0.020900\n",
      "HM_CHARGED                   12.095000\n",
      "LIME                          1.013000\n",
      "IRON_ORE                      3.081500\n",
      "OXY                         573.250000\n",
      "SCRAP                         6.320000\n",
      "SCRAP_HVY_MELT                7.192500\n",
      "SCRAP_WRP_OH_GRADE_FINES      6.000000\n",
      "TD_P                          0.009000\n",
      "TD_C                          0.017000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#We will use the approach of finding the outliers on the basis of interquantile range\n",
    "Q1 = data.quantile(0.25)\n",
    "Q3 = data.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAST_NO</th>\n",
       "      <th>GRADE</th>\n",
       "      <th>BLOW_DUR</th>\n",
       "      <th>MIXER_C</th>\n",
       "      <th>MIXER_MN</th>\n",
       "      <th>MIXER_S</th>\n",
       "      <th>MIXER_P</th>\n",
       "      <th>MIXER_SI</th>\n",
       "      <th>MIXER_TI</th>\n",
       "      <th>HM_CHARGED</th>\n",
       "      <th>LIME</th>\n",
       "      <th>IRON_ORE</th>\n",
       "      <th>OXY</th>\n",
       "      <th>SCRAP</th>\n",
       "      <th>SCRAP_HVY_MELT</th>\n",
       "      <th>SCRAP_WRP_OH_GRADE_FINES</th>\n",
       "      <th>TD_P</th>\n",
       "      <th>TD_C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M44919</td>\n",
       "      <td>980</td>\n",
       "      <td>18.766667</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>140.00</td>\n",
       "      <td>8.498</td>\n",
       "      <td>2.906</td>\n",
       "      <td>7897</td>\n",
       "      <td>21.10</td>\n",
       "      <td>3.10</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M44923</td>\n",
       "      <td>980</td>\n",
       "      <td>18.183333</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.1870</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>140.22</td>\n",
       "      <td>8.590</td>\n",
       "      <td>3.000</td>\n",
       "      <td>7354</td>\n",
       "      <td>21.50</td>\n",
       "      <td>3.50</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M44925</td>\n",
       "      <td>980</td>\n",
       "      <td>18.166667</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0780</td>\n",
       "      <td>0.1900</td>\n",
       "      <td>0.8090</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>144.96</td>\n",
       "      <td>8.807</td>\n",
       "      <td>3.165</td>\n",
       "      <td>7624</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M44935</td>\n",
       "      <td>1019</td>\n",
       "      <td>19.016667</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.5950</td>\n",
       "      <td>0.0594</td>\n",
       "      <td>143.03</td>\n",
       "      <td>8.294</td>\n",
       "      <td>2.488</td>\n",
       "      <td>7467</td>\n",
       "      <td>20.63</td>\n",
       "      <td>5.63</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M44940</td>\n",
       "      <td>980</td>\n",
       "      <td>16.900000</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.5530</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>166.86</td>\n",
       "      <td>8.548</td>\n",
       "      <td>5.696</td>\n",
       "      <td>7088</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>M60321</td>\n",
       "      <td>980</td>\n",
       "      <td>16.333333</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.1704</td>\n",
       "      <td>0.9286</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>144.15</td>\n",
       "      <td>8.187</td>\n",
       "      <td>7.589</td>\n",
       "      <td>7188</td>\n",
       "      <td>15.16</td>\n",
       "      <td>5.16</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>M60325</td>\n",
       "      <td>909</td>\n",
       "      <td>16.683333</td>\n",
       "      <td>4.29</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.0400</td>\n",
       "      <td>0.1679</td>\n",
       "      <td>0.5499</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>146.63</td>\n",
       "      <td>8.773</td>\n",
       "      <td>5.846</td>\n",
       "      <td>7540</td>\n",
       "      <td>15.81</td>\n",
       "      <td>5.81</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>M60330</td>\n",
       "      <td>909</td>\n",
       "      <td>15.850000</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1736</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>152.37</td>\n",
       "      <td>8.629</td>\n",
       "      <td>8.269</td>\n",
       "      <td>6724</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>M60344</td>\n",
       "      <td>980</td>\n",
       "      <td>16.850000</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>0.1573</td>\n",
       "      <td>0.6491</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>158.69</td>\n",
       "      <td>10.217</td>\n",
       "      <td>11.905</td>\n",
       "      <td>7234</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>M60348</td>\n",
       "      <td>980</td>\n",
       "      <td>16.350000</td>\n",
       "      <td>4.62</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.7617</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>155.95</td>\n",
       "      <td>9.029</td>\n",
       "      <td>8.645</td>\n",
       "      <td>6867</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6443 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CAST_NO  GRADE   BLOW_DUR  MIXER_C  MIXER_MN  MIXER_S  MIXER_P  MIXER_SI  \\\n",
       "0     M44919    980  18.766667     4.48    0.0460   0.0590   0.1940    0.6450   \n",
       "1     M44923    980  18.183333     4.48    0.0460   0.0500   0.1870    0.6790   \n",
       "2     M44925    980  18.166667     4.48    0.0420   0.0780   0.1900    0.8090   \n",
       "6     M44935   1019  19.016667     4.48    0.0430   0.0440   0.1560    0.5950   \n",
       "9     M44940    980  16.900000     4.48    0.0420   0.0530   0.2000    0.5530   \n",
       "...      ...    ...        ...      ...       ...      ...      ...       ...   \n",
       "8143  M60321    980  16.333333     4.65    0.0529   0.0250   0.1704    0.9286   \n",
       "8144  M60325    909  16.683333     4.29    0.0438   0.0400   0.1679    0.5499   \n",
       "8145  M60330    909  15.850000     4.48    0.0434   0.0368   0.1736    0.7030   \n",
       "8146  M60344    980  16.850000     4.55    0.0431   0.0510   0.1573    0.6491   \n",
       "8147  M60348    980  16.350000     4.62    0.0431   0.0410   0.1773    0.7617   \n",
       "\n",
       "      MIXER_TI  HM_CHARGED    LIME  IRON_ORE   OXY  SCRAP  SCRAP_HVY_MELT  \\\n",
       "0       0.0655      140.00   8.498     2.906  7897  21.10            3.10   \n",
       "1       0.0656      140.22   8.590     3.000  7354  21.50            3.50   \n",
       "2       0.0700      144.96   8.807     3.165  7624  20.00            0.00   \n",
       "6       0.0594      143.03   8.294     2.488  7467  20.63            5.63   \n",
       "9       0.0517      166.86   8.548     5.696  7088   0.00            0.00   \n",
       "...        ...         ...     ...       ...   ...    ...             ...   \n",
       "8143    0.0995      144.15   8.187     7.589  7188  15.16            5.16   \n",
       "8144    0.0634      146.63   8.773     5.846  7540  15.81            5.81   \n",
       "8145    0.0709      152.37   8.629     8.269  6724   0.00            0.00   \n",
       "8146    0.0631      158.69  10.217    11.905  7234   0.00            0.00   \n",
       "8147    0.0723      155.95   9.029     8.645  6867   0.00            0.00   \n",
       "\n",
       "      SCRAP_WRP_OH_GRADE_FINES   TD_P   TD_C  \n",
       "0                         18.0  0.010  0.042  \n",
       "1                         18.0  0.021  0.050  \n",
       "2                         20.0  0.022  0.053  \n",
       "6                         15.0  0.017  0.080  \n",
       "9                          0.0  0.016  0.050  \n",
       "...                        ...    ...    ...  \n",
       "8143                       5.0  0.015  0.052  \n",
       "8144                       5.0  0.020  0.048  \n",
       "8145                       0.0  0.016  0.057  \n",
       "8146                       0.0  0.020  0.074  \n",
       "8147                       0.0  0.018  0.075  \n",
       "\n",
       "[6443 rows x 18 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This dataset is without outliers which we removed by usinh dfi = data[((data < (Q1 - 1.5 * IQR)) |(data > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "dfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6443 entries, 0 to 8147\n",
      "Data columns (total 18 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   CAST_NO                   6443 non-null   object \n",
      " 1   GRADE                     6443 non-null   int64  \n",
      " 2   BLOW_DUR                  6443 non-null   float64\n",
      " 3   MIXER_C                   6443 non-null   float64\n",
      " 4   MIXER_MN                  6434 non-null   float64\n",
      " 5   MIXER_S                   6443 non-null   float64\n",
      " 6   MIXER_P                   6434 non-null   float64\n",
      " 7   MIXER_SI                  6434 non-null   float64\n",
      " 8   MIXER_TI                  6434 non-null   float64\n",
      " 9   HM_CHARGED                6443 non-null   float64\n",
      " 10  LIME                      6443 non-null   float64\n",
      " 11  IRON_ORE                  6443 non-null   float64\n",
      " 12  OXY                       6443 non-null   int64  \n",
      " 13  SCRAP                     6443 non-null   float64\n",
      " 14  SCRAP_HVY_MELT            6443 non-null   float64\n",
      " 15  SCRAP_WRP_OH_GRADE_FINES  6443 non-null   float64\n",
      " 16  TD_P                      6443 non-null   float64\n",
      " 17  TD_C                      6443 non-null   float64\n",
      "dtypes: float64(15), int64(2), object(1)\n",
      "memory usage: 956.4+ KB\n"
     ]
    }
   ],
   "source": [
    "dfi.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For treating the null values,we will fill the null values with median.\n",
    "dfi[\"MIXER_MN\"].fillna(dfi[\"MIXER_MN\"].median(), inplace=True)\n",
    "dfi[\"MIXER_P\"].fillna(dfi[\"MIXER_P\"].median(), inplace=True)\n",
    "dfi[\"MIXER_SI\"].fillna(dfi[\"MIXER_SI\"].median(), inplace=True)\n",
    "dfi[\"MIXER_TI\"].fillna(dfi[\"MIXER_TI\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Feature Matrix is - (6443, 17)\n"
     ]
    }
   ],
   "source": [
    "df=dfi.drop('TD_P',axis=1)\n",
    "df=dfi.drop('TD_C',axis=1)\n",
    "df=dfi.drop('CAST_NO',axis=1)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_std = StandardScaler().fit_transform(df)\n",
    "\n",
    "print (\"The shape of Feature Matrix is -\",X_std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X_std\n",
    "y=dfi['TD_P']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.956864522586654\n",
      "{'n_estimators': 30, 'max_features': 8}\n"
     ]
    }
   ],
   "source": [
    "#Applying the Random forest regression along with hyperparameter tuning using RandomsearchCV. Below are the hypermaters that can be used for traing from which the best ones are to be chosen.from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "forest_reg = RandomForestRegressor()\n",
    "grid_search = RandomizedSearchCV(forest_reg, param_grid, cv=5,\n",
    "                          scoring='r2')\n",
    "grid_search.fit(X_train,y_train)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0001 degrees.\n",
      "Accuracy = 99.32%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "best_random = grid_search\n",
    "random_accuracy = evaluate(best_random, X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00\n",
      "RS: 1.00\n"
     ]
    }
   ],
   "source": [
    "#Checking with SGD Regression algorithm\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(alpha=0.0001, epsilon=0.1, eta0=0.01, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='invscaling', loss='squared_loss', penalty='l2', power_t=0.25, random_state=None,\n",
    "       shuffle=False, verbose=0, warm_start=False)\n",
    "sgd_reg.fit(X_train, y_train)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"MSE: %.2f\" % mse)\n",
    "from sklearn.metrics import r2_score\n",
    "rs = r2_score(y_test, y_pred)\n",
    "print(\"RS: %.2f\" % rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.6748 degrees.\n",
      "Accuracy = -3541.26%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "best_random = sgd_reg\n",
    "random_accuracy = evaluate(best_random, X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                    colsample_bylevel=1, colsample_bynode=1,\n",
       "                                    colsample_bytree=1, gamma=0,\n",
       "                                    importance_type='gain', learning_rate=0.1,\n",
       "                                    max_delta_step=0, max_depth=3,\n",
       "                                    min_child_weight=1, missing=None,\n",
       "                                    n_estimators=100, n_jobs=1, nthread=None,\n",
       "                                    objective='reg:linear', random_state=0,\n",
       "                                    reg_alpha=0, reg...\n",
       "                                    scale_pos_weight=1, seed=None, silent=None,\n",
       "                                    subsample=1, verbosity=1),\n",
       "             iid='deprecated', n_jobs=5,\n",
       "             param_grid={'colsample_bytree': [0.7],\n",
       "                         'learning_rate': [0.03, 0.05, 0.07],\n",
       "                         'max_depth': [5, 6, 7], 'min_child_weight': [4],\n",
       "                         'n_estimators': [500], 'nthread': [4],\n",
       "                         'objective': ['reg:linear'], 'silent': [1],\n",
       "                         'subsample': [0.7]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking with XGBRegressor algorithm\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n",
    "xgb1 = XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:linear'],\n",
    "              'learning_rate': [.03, 0.05, .07], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [500]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 10,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=0)\n",
    "\n",
    "xgb_grid.fit(X_train,\n",
    "         y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.7,\n",
       " 'learning_rate': 0.07,\n",
       " 'max_depth': 6,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 500,\n",
       " 'nthread': 4,\n",
       " 'objective': 'reg:linear',\n",
       " 'silent': 1,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0001 degrees.\n",
      "Accuracy = 99.70%.\n",
      "R2: 1.00\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "best_random = xgb_grid.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_train,y_train)\n",
    "y_pred = best_random.predict(X_test)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R2: %.2f\" % r2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                             max_iter=None, normalize=False, random_state=None,\n",
       "                             solver='auto', tol=0.001),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': array([1.e+00, 1.e-01, 1.e-02, 1.e-03, 1.e-04, 0.e+00])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking with the Ridge regression algorithm\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# load the diabetes datasets\n",
    "\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance\n",
      "Average Error: 0.0000 degrees.\n",
      "Accuracy = 100.00%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(predictions - test_labels)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "best_random = grid.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking these models, we can say that might be there can be an overfitting therefor we will consider RandomforestRegressor with the score 0.956."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
